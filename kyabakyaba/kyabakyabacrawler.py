import requests
from bs4 import BeautifulSoup
import time
import json


def scrape_cabacaba():
    print("ğŸŒ¸ C-chan: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ï¼")

    # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®URL
    url = "https://www.caba2.net/tokyo/_list"

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        stores_data = []
        count = 0

        # åº—èˆ—æƒ…å ±ã‚’å«ã‚€divè¦ç´ ã‚’å–å¾—
        club_tops = soup.select("div.club-top")
        store_infos = soup.select("div.list-info")

        # æœ€åˆã®5ä»¶ã®åº—èˆ—æƒ…å ±ã‚’å–å¾—
        for club_top, store_info in zip(club_tops[:5], store_infos[:5]):
            store_data = {
                "name": "",
                "area": "",
                "business_hours": "",
                "holiday": "",
                "budget": "",
                "phone": "",
                "address": "",
            }

            # åº—èˆ—åã¨ã‚¨ãƒªã‚¢ã‚’å–å¾—
            text_wrapper = club_top.select_one("div.text-wrapper")
            if text_wrapper:
                # åº—èˆ—åã‚’å–å¾—
                blog_title = text_wrapper.select_one("h2.blog-title a.link")
                if blog_title:
                    store_data["name"] = blog_title.text.strip()

                # ã‚¨ãƒªã‚¢ã‚’å–å¾—
                area_text = text_wrapper.select_one("p.comment")
                if area_text:
                    # "ã®ã‚­ãƒ£ãƒã‚¯ãƒ©"ã‚’é™¤å»ã—ã¦ã‚¨ãƒªã‚¢ã®ã¿ã‚’å–å¾—
                    area = area_text.text.replace("ã®ã‚­ãƒ£ãƒã‚¯ãƒ©", "").strip()
                    store_data["area"] = area

            # ãã®ä»–ã®æƒ…å ±ã‚’å–å¾—
            info_items = store_info.select("ul li")
            for item in info_items:
                label = item.select_one("label.text")
                value = item.select_one("span.show")

                if label and value:
                    label_text = label.text.strip()
                    value_text = value.text.strip()

                    if "å–¶æ¥­æ™‚é–“" in label_text:
                        store_data["business_hours"] = value_text
                    elif "åº—ä¼‘æ—¥" in label_text:
                        store_data["holiday"] = value_text
                    elif "äºˆç®—ç›®å®‰" in label_text:
                        # ç¨è¾¼æƒ…å ±ã‚‚å«ã‚ã¦å–å¾—
                        tax_info = value.select_one("span.tax-service-fee")
                        if tax_info:
                            store_data["budget"] = (
                                f"{value_text.replace(tax_info.text, '')} {tax_info.text.strip()}"
                            )
                        else:
                            store_data["budget"] = value_text
                    elif "é›»è©±ç•ªå·" in label_text:
                        store_data["phone"] = value_text
                    elif "æ‰€åœ¨åœ°" in label_text:
                        store_data["address"] = value_text

            stores_data.append(store_data)
            count += 1

            print(f"\nâœ¨ åº—èˆ—æƒ…å ± {count}:")
            print(f"ğŸ“ åº—èˆ—å: {store_data['name']}")
            print(f"ğŸ¢ ã‚¨ãƒªã‚¢: {store_data['area']}")
            print(f"ğŸ•’ å–¶æ¥­æ™‚é–“: {store_data['business_hours']}")
            print(f"ğŸ“… å®šä¼‘æ—¥: {store_data['holiday']}")
            print(f"ğŸ’° äºˆç®—: {store_data['budget']}")
            print(f"ğŸ“± é›»è©±: {store_data['phone']}")
            print(f"ğŸ  ä½æ‰€: {store_data['address']}")

        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_file = "cabacaba_stores.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(stores_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ‰ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼ {count}ä»¶ã®åº—èˆ—æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        print(f"ğŸ“ çµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")


if __name__ == "__main__":
    scrape_cabacaba()
