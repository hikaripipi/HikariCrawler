import time
import csv
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup


def scrape_cabacaba():
    print("ğŸŒ¸ C-chan: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ï¼")

    url = "https://www.caba2.net/tokyo/_list"
    options = Options()
    options.add_argument("--headless")  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    # ChromeDriverã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
    service = Service(
        executable_path="/usr/local/bin/chromedriver"
    )  # ã“ã“ã«ChromeDriverã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ã­
    driver = webdriver.Chrome(service=service, options=options)

    try:
        driver.get(url)
        wait = WebDriverWait(driver, 10)

        # 100ä»¶å–å¾—ã™ã‚‹ãŸã‚ã«ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        while True:
            try:
                load_more_button = wait.until(
                    EC.element_to_be_clickable((By.CLASS_NAME, "load-more__btn"))
                )
                load_more_button.click()
                time.sleep(2)  # ãƒšãƒ¼ã‚¸ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã®ã‚’å¾…ã¤
            except Exception as e:
                print("âŒ ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                break

            # 100ä»¶ä»¥ä¸Šè¡¨ç¤ºã•ã‚ŒãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            soup = BeautifulSoup(driver.page_source, "html.parser")
            if len(soup.select("div.club-top")) >= 100:
                break

        soup = BeautifulSoup(driver.page_source, "html.parser")
        stores_data = []
        seen_names = set()
        count = 0

        club_tops = soup.select("div.club-top")
        store_infos = soup.select("div.list-info")

        for club_top, store_info in zip(club_tops[:100], store_infos[:100]):
            store_data = {
                "name": "",
                "kana": "",
                "area": "",
                "type": "",
                "business_hours": "",
                "holiday": "",
                "budget": "",
                "phone": "",
                "address": "",
            }

            text_wrapper = club_top.select_one("div.text-wrapper")
            if text_wrapper:
                blog_title = text_wrapper.select_one("h2.blog-title a.link")
                if blog_title:
                    full_name = blog_title.text.strip()
                    if full_name in seen_names:
                        continue
                    seen_names.add(full_name)

                    # åº—èˆ—åã¨èª­ã¿ä»®åã‚’åˆ†ã‘ã‚‹
                    if " - " in full_name:
                        store_data["name"], store_data["kana"] = full_name.split(" - ")

                area_text = text_wrapper.select_one("p.comment")
                if area_text:
                    full_area = area_text.text.strip()
                    # ã‚¨ãƒªã‚¢ã¨åº—èˆ—ç¨®é¡ã‚’åˆ†ã‘ã‚‹
                    if "ã®" in full_area:
                        store_data["area"], store_data["type"] = full_area.split("ã®")

            info_items = store_info.select("ul li")
            for item in info_items:
                label = item.select_one("label.text")
                value = item.select_one("span.show")

                if label and value:
                    label_text = label.text.strip()
                    value_text = value.text.strip()

                    if "å–¶æ¥­æ™‚é–“" in label_text:
                        store_data["business_hours"] = value_text
                    elif "åº—ä¼‘æ—¥" in label_text:
                        store_data["holiday"] = value_text
                    elif "äºˆç®—ç›®å®‰" in label_text:
                        tax_info = value.select_one("span.tax-service-fee")
                        if tax_info:
                            store_data["budget"] = (
                                f"{value_text.replace(tax_info.text, '')} {tax_info.text.strip()}"
                            )
                        else:
                            store_data["budget"] = value_text
                    elif "é›»è©±ç•ªå·" in label_text:
                        store_data["phone"] = value_text
                    elif "æ‰€åœ¨åœ°" in label_text:
                        store_data["address"] = value_text

            stores_data.append(store_data)
            count += 1

            print(f"\nâœ¨ åº—èˆ—æƒ…å ± {count}:")
            print(f"ğŸ“ åº—èˆ—å: {store_data['name']}")
            print(f"ğŸ“– èª­ã¿ä»®å: {store_data['kana']}")
            print(f"ğŸ¢ ã‚¨ãƒªã‚¢: {store_data['area']}")
            print(f"ğŸ·ï¸ åº—èˆ—ç¨®é¡: {store_data['type']}")
            print(f"ğŸ•’ å–¶æ¥­æ™‚é–“: {store_data['business_hours']}")
            print(f"ğŸ“… å®šä¼‘æ—¥: {store_data['holiday']}")
            print(f"ğŸ’° äºˆç®—: {store_data['budget']}")
            print(f"ğŸ“± é›»è©±: {store_data['phone']}")
            print(f"ğŸ  ä½æ‰€: {store_data['address']}")

        # CSVã«ä¿å­˜
        output_file = "cabacaba_stores.csv"
        with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
            fieldnames = [
                "name",
                "kana",
                "area",
                "type",
                "business_hours",
                "holiday",
                "budget",
                "phone",
                "address",
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            for store in stores_data:
                writer.writerow(store)

        print(f"\nğŸ‰ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼ {count}ä»¶ã®åº—èˆ—æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        print(f"ğŸ“ çµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")

    finally:
        driver.quit()


if __name__ == "__main__":
    scrape_cabacaba()
